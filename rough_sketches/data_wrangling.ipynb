{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, LSTM, Embedding, Dense, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_components import preprocess_sentence, get_angles, positional_encoding, create_padding_mask, create_look_ahead_mask, \\\n",
    "                                    FullyConnected, EncoderLayer, Encoder, DecoderLayer, Decoder, Transformer, CustomSchedule, \\\n",
    "                                        create_train_tokenizer, load_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, ByteLevelBPETokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load and pre-process European parliament data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "\treturn doc.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_en = 'europarl_de-en/europarl-v7.de-en.en'\n",
    "text_en = load_doc(filename_en)\n",
    "doc_en = to_sentences(text_en)\n",
    "\n",
    "filename_de = 'europarl_de-en/europarl-v7.de-en.de'\n",
    "text_de = load_doc(filename_de)\n",
    "doc_de = to_sentences(text_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_languages = zip(doc_de, doc_en)\n",
    "df_euro_parl = pd.DataFrame(both_languages, columns = ['german', 'english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty strings with NaN\n",
    "df_euro_parl['german'].replace('', np.nan, inplace=True)\n",
    "df_euro_parl['english'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2923, 8366)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of NaN values\n",
    "df_euro_parl['german'].isna().sum(), df_euro_parl['english'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values\n",
    "df_euro_parl = df_euro_parl.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load and PreProcess ManyThings data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ManyThings = pd.read_table('deu-eng/deu.txt', names=['eng', 'deu', 'attr'])\n",
    "df_ManyThings = df_ManyThings.drop('attr',axis = 1).rename(columns = {'eng':'english', 'deu':'german'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ManyThings['english'] = df_ManyThings['english'].apply(preprocess_sentence)\n",
    "#df_ManyThings['german'] = df_ManyThings['german'].apply(preprocess_sentence)\n",
    "\n",
    "# switch order of columns\n",
    "df_ManyThings = df_ManyThings[['german', 'english']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty strings with NaN\n",
    "df_ManyThings['german'].replace('', np.nan, inplace=True)\n",
    "df_ManyThings['english'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of NaN values\n",
    "df_ManyThings['german'].isna().sum(), df_ManyThings['english'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Combine two dataframes </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.concat([df_euro_parl, df_ManyThings], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>german</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251715</th>\n",
       "      <td>Wenn jemand Fremdes dir sagt, dass du dich wie...</td>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251716</th>\n",
       "      <td>Wenn jemand, der nicht weiß, woher man kommt, ...</td>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251717</th>\n",
       "      <td>Es ist wohl unmöglich, einen vollkommen fehler...</td>\n",
       "      <td>It may be impossible to get a completely error...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251718</th>\n",
       "      <td>Ich weiß wohl, dass das ausschließliche Beitra...</td>\n",
       "      <td>I know that adding sentences only in your nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251719</th>\n",
       "      <td>Ohne Zweifel findet sich auf dieser Welt zu je...</td>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   german  \\\n",
       "251715  Wenn jemand Fremdes dir sagt, dass du dich wie...   \n",
       "251716  Wenn jemand, der nicht weiß, woher man kommt, ...   \n",
       "251717  Es ist wohl unmöglich, einen vollkommen fehler...   \n",
       "251718  Ich weiß wohl, dass das ausschließliche Beitra...   \n",
       "251719  Ohne Zweifel findet sich auf dieser Welt zu je...   \n",
       "\n",
       "                                                  english  \n",
       "251715  If someone who doesn't know your background sa...  \n",
       "251716  If someone who doesn't know your background sa...  \n",
       "251717  It may be impossible to get a completely error...  \n",
       "251718  I know that adding sentences only in your nati...  \n",
       "251719  Doubtless there exists in this world precisely...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "df_complete['german'] = df_complete['german'].apply(preprocess_sentence)\n",
    "df_complete['english'] = df_complete['english'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lassen Sie mich das begruenden.\n",
      "I would like to explain our thinking here.\n",
      "Es geht uns erstens um eine ordnungsgemaesse Verwendung der Mittel aus den Struktur- und dem Kohaesionsfonds.\n",
      "Firstly, we are concerned with the proper use of the Structural and Cohesion Funds.\n"
     ]
    }
   ],
   "source": [
    "for i in range (498,500):\n",
    "    print(df_complete.iloc[i,0])\n",
    "    print( df_complete.iloc[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create english corpus and german corpus </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create corpus for english and german to train BPE tokenizers on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('corpus/en_corpus.txt', 'w') as f:\n",
    "    for idx, row in df_complete.iterrows():\n",
    "        f.write(row['english'] + ' \\n')\n",
    "\n",
    "with open ('corpus/de_corpus.txt', 'w') as f:\n",
    "    for idx, row in df_complete.iterrows():\n",
    "        f.write(row['german'] + ' \\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run time: 1m 16 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create bpe_tokenizers </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "json file saved at: tokenizer_en_corpus.json\n",
      "\n",
      "\n",
      "\n",
      "json file saved at: tokenizer_de_corpus.json\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = create_train_tokenizer(['en_corpus.txt'])\n",
    "de_tokenizer = create_train_tokenizer(['de_corpus.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['start_',\n",
       "  'In',\n",
       "  'Ġdiesem',\n",
       "  'ĠSinne',\n",
       "  'Ġ,',\n",
       "  'Ġmoechte',\n",
       "  'Ġich',\n",
       "  'ĠSie',\n",
       "  'Ġbitten',\n",
       "  ',',\n",
       "  'Ġnur',\n",
       "  'Ġauf',\n",
       "  'Ġkurz',\n",
       "  'erer',\n",
       "  'ĠZeit',\n",
       "  'Ġeine',\n",
       "  'ĠMa',\n",
       "  'il',\n",
       "  'Ġzu',\n",
       "  'Ġschicken',\n",
       "  '.',\n",
       "  '_end'],\n",
       " [1,\n",
       "  759,\n",
       "  629,\n",
       "  3084,\n",
       "  4034,\n",
       "  585,\n",
       "  406,\n",
       "  591,\n",
       "  3197,\n",
       "  14,\n",
       "  631,\n",
       "  359,\n",
       "  1872,\n",
       "  8016,\n",
       "  838,\n",
       "  390,\n",
       "  1014,\n",
       "  473,\n",
       "  300,\n",
       "  12795,\n",
       "  16,\n",
       "  2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test tokenizers\n",
    "en_tokenizer, en_word_index = load_tokenizer('tokenizer_en_corpus.json')\n",
    "de_tokenizer, de_word_index = load_tokenizer('tokenizer_de_corpus.json')\n",
    "sentence = \"In diesem      Sinne   , möchte ich Sie bitten, nur auf kurzerer Zeit eine Mail zu schicken.\"\n",
    "sentence = preprocess_sentence(sentence)\n",
    "output = de_tokenizer.encode(sentence)\n",
    "output.tokens, output.ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save df_complete as csv file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv('df_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.read_csv('df_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "german     2\n",
       "english    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mysteriously, there are two nan values. We'll simply drop them.\n",
    "df_complete = df_complete.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv('df_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create version of dataframe with capped sentence length </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_30 = df_complete.copy(deep = True)\n",
    "df_complete_30['german_length'] = df_complete['german'].apply(lambda x: len(x.split(' ')))\n",
    "df_complete_30['english_length'] = df_complete['english'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>german</th>\n",
       "      <th>english</th>\n",
       "      <th>german_length</th>\n",
       "      <th>english_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erklaere die am Freitag, dem 17. Dezember ...</td>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie Sie feststellen konnten, ist der gefuercht...</td>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Im Parlament besteht der Wunsch nach einer Aus...</td>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heute moechte ich Sie bitten - das ist auch de...</td>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              german  \\\n",
       "0                 Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erklaere die am Freitag, dem 17. Dezember ...   \n",
       "2  Wie Sie feststellen konnten, ist der gefuercht...   \n",
       "3  Im Parlament besteht der Wunsch nach einer Aus...   \n",
       "4  Heute moechte ich Sie bitten - das ist auch de...   \n",
       "\n",
       "                                             english  german_length  \\\n",
       "0                          Resumption of the session              3   \n",
       "1  I declare resumed the session of the European ...             29   \n",
       "2  Although, as you will have seen, the dreaded '...             22   \n",
       "3  You have requested a debate on this subject in...             16   \n",
       "4  In the meantime, I should like to observe a mi...             33   \n",
       "\n",
       "   english_length  \n",
       "0               4  \n",
       "1              38  \n",
       "2              31  \n",
       "3              19  \n",
       "4              40  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_30 = (df_complete_30['german_length'] <= 30) & (df_complete_30['english_length'] <= 30)\n",
    "df_complete_30 = df_complete_30[mask_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160638, 1562141)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_complete), len(df_complete_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_30.to_csv('df_complete_30.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a30d934768a106a0bdaa0b54b1b0ce58ac936216b32c4f047caaf50b54e34c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
