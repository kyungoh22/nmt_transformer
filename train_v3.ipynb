{"cells":[{"cell_type":"markdown","metadata":{},"source":["- run following cell when training on colab"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#! pip install tokenizers===0.9.3\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","# %cd gdrive/MyDrive/Colab Notebooks/colab_upload"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2614,"status":"ok","timestamp":1660753571224,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"Mj4NcfcoYGfw"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","import time\n","import os\n","\n","# My custom modules\n","from tokenizer_helpers import load_tokenizer\n","from model_components import Transformer\n","from training_helper_functions import loss_function, accuracy_function, compute_test_metrics, CustomSchedule"]},{"cell_type":"markdown","metadata":{},"source":["- run following cell when training on colab"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df_en_de = pd.read_csv('/content/gdrive/MyDrive/transformer_nmt_dataset/df_complete_30.csv')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3106,"status":"ok","timestamp":1660753576484,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"fMfUbKk5YGfx","outputId":"7473f42b-1584-4793-ef29-cfca39448a9b"},"outputs":[],"source":["df_en_de = pd.read_csv('./data/df_complete_30.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":728,"status":"ok","timestamp":1660753578742,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"G3QynPgBiTGR"},"outputs":[],"source":["pairs = df_en_de\n","\n","## Select small fraction for testing purposes\n","#pairs = pairs.sample(frac = 0.002)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>german</th>\n","      <th>english</th>\n","      <th>german_length</th>\n","      <th>english_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1233401</th>\n","      <td>Strenge Haushaltsdisziplin ist kein Synonym fu...</td>\n","      <td>Rigour is not synonymous with saving.</td>\n","      <td>7</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1484698</th>\n","      <td>Wir wissen, was am letzten Wochenende passiert...</td>\n","      <td>We know what happened last weekend.</td>\n","      <td>8</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>194333</th>\n","      <td>Wir brauchen Wettbewerb, und ich hoffe, meine ...</td>\n","      <td>We need competition, and I hope that my Britis...</td>\n","      <td>16</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>775447</th>\n","      <td>Es ist wichtig, all diese Aktionen zu koordini...</td>\n","      <td>It is important that these operations are coor...</td>\n","      <td>8</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1440351</th>\n","      <td>Ich sah ihn beim Ueberqueren der Strasse.</td>\n","      <td>I saw him crossing the street.</td>\n","      <td>7</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    german  \\\n","1233401  Strenge Haushaltsdisziplin ist kein Synonym fu...   \n","1484698  Wir wissen, was am letzten Wochenende passiert...   \n","194333   Wir brauchen Wettbewerb, und ich hoffe, meine ...   \n","775447   Es ist wichtig, all diese Aktionen zu koordini...   \n","1440351          Ich sah ihn beim Ueberqueren der Strasse.   \n","\n","                                                   english  german_length  \\\n","1233401              Rigour is not synonymous with saving.              7   \n","1484698                We know what happened last weekend.              8   \n","194333   We need competition, and I hope that my Britis...             16   \n","775447   It is important that these operations are coor...              8   \n","1440351                     I saw him crossing the street.              7   \n","\n","         english_length  \n","1233401               6  \n","1484698               6  \n","194333               16  \n","775447                8  \n","1440351               6  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["pairs.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["3124"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(pairs)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# load pre-trained tokenizers for de and en\n","en_tokenizer, en_word_index = load_tokenizer('tokenizers/tokenizer_en_corpus.json')\n","de_tokenizer, de_word_index = load_tokenizer('tokenizers/tokenizer_de_corpus.json')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1660753582823,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"yqt2dREtYGf2","outputId":"fbe3bfac-f1c9-451e-be88-be55f2cb6ef4"},"outputs":[{"name":"stdout","output_type":"stream","text":["29999 29999\n"]}],"source":["vocab_len_source = len(de_word_index.keys())\n","vocab_len_target = len(en_word_index.keys())\n","\n","print (vocab_len_source, vocab_len_target)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1660753584488,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"pSFERvXSYGf2"},"outputs":[],"source":["# add 1 for zero-padding in embedding layer\n","num_tokens_source = vocab_len_source + 1\n","num_tokens_target = vocab_len_target + 1"]},{"cell_type":"markdown","metadata":{},"source":["- Tokenize the data using the pre-trained tokenizers"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["source_de = []\n","target_en = []\n","\n","# iterrate over every row of dataframe \"pairs\"\n","for idx, row in pairs.iterrows():\n","    string_de = row['german']\n","    string_en = row['english']\n","\n","    if type(string_de) == str and type(string_en) == str:\n","        # encode\n","        encoding_de = de_tokenizer.encode(string_de)\n","        encoding_en = en_tokenizer.encode(string_en)\n","        # retrieve ids (integers) and append to list\n","        source_de.append(encoding_de.ids)\n","        target_en.append(encoding_en.ids)"]},{"cell_type":"markdown","metadata":{},"source":["- run time for 100% of df_complete_30: 4m 10s"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# convert to tensors with zero-padding\n","source_tensor = tf.keras.preprocessing.sequence.pad_sequences(source_de, padding = 'post')\n","target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_en, padding = 'post')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1660753584986,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"kc2sAiaSYGf3"},"outputs":[],"source":["# split into training and test sets\n","source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor = train_test_split(\n","                                                                source_tensor, target_tensor, test_size=0.05\n","                                                                )"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["'Ich hoffe, dass die Entschliessung ueber Belarus einer von vielen Schritten ist, die wir noch setzen werden.'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["de_tokenizer.decode(source_train_tensor[10])"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1660753586587,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"TJRmvHIIYGf3","outputId":"d28d1478-95f4-4283-e080-c639e54a2394"},"outputs":[],"source":["# For first run-through:\n","# save numpy array as csv file:\n","\n","os.mkdir('tensors')\n","\n","np.savetxt('tensors/source_train_tensor.csv', source_train_tensor, delimiter = ',')\n","np.savetxt('tensors/source_test_tensor.csv', source_test_tensor, delimiter = ',')\n","np.savetxt('tensors/target_train_tensor.csv', target_train_tensor, delimiter = ',')\n","np.savetxt('tensors/target_test_tensor.csv', target_test_tensor, delimiter = ',')\n"]},{"cell_type":"markdown","metadata":{},"source":["- run time for 100% of df_complete_30: 3m"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mask_source = np.random.choice([False, True], len(source_train_tensor), p=[0.999, 0.001])\n","\n","source_train_sample = source_train_tensor[mask_source]\n","target_train_sample = target_train_tensor[mask_source]\n","\n","np.savetxt('tensors/source_train_sample.csv', source_train_sample, delimiter = ',')\n","np.savetxt('tensors/target_train_sample.csv', target_train_sample, delimiter = ',')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# When picking up training again after an interruption, you need to work with the same training and test sets.\n","# Load saved numpy arrays\n","\n","\n","# source_train_tensor = np.loadtxt('tensors/source_train_tensor.csv', delimiter = ',', dtype = 'int32')\n","# source_test_tensor = np.loadtxt('tensors/source_test_tensor.csv', delimiter = ',', dtype = 'int32')\n","# target_train_tensor = np.loadtxt('tensors/target_train_tensor.csv', delimiter = ',', dtype = 'int32')\n","# target_test_tensor = np.loadtxt('tensors/target_test_tensor.csv', delimiter = ',', dtype = 'int32')"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1660753586587,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"A2NUoadXYGf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["49 47\n"]}],"source":["max_source_length= max(len(t) for t in np.concatenate((source_train_tensor, source_test_tensor), axis=0))\n","max_target_length= max(len(t) for t in np.concatenate((target_train_tensor, target_test_tensor), axis=0))\n","\n","print(max_source_length, max_target_length)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":877,"status":"ok","timestamp":1660753588160,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"igd_hwb9iTGU"},"outputs":[],"source":["BATCH_SIZE = 32\n","#Create training dataset and shuffle\n","dataset_train = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BATCH_SIZE)\n","# divide into batches\n","dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n","\n","#Create test dataset\n","dataset_test = tf.data.Dataset.from_tensor_slices((source_test_tensor, target_test_tensor)).shuffle(BATCH_SIZE)\n","dataset_test = dataset_test.batch(BATCH_SIZE, drop_remainder=True)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385,"status":"ok","timestamp":1660753588911,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"vtr_qVkriTGV","outputId":"14da9cc9-dd30-4323-b623-edd9031c361f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 49) (32, 47)\n"]}],"source":["source_batch_train, target_batch_train =next(iter(dataset_train))\n","print(source_batch_train.shape, target_batch_train.shape)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EhuSjWSkYGf4"},"source":["<h3> Define arguments for Transformer object </h3>"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":242,"status":"ok","timestamp":1660755527254,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"mgZTVQLSYGf4"},"outputs":[],"source":["# Transformer arguments: \n","# num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, \n","# target_vocab_size, max_positional_encoding_input,\n","# max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6\n","\n","num_layers = 4\n","embedding_dim = 64\n","num_heads = 5\n","fully_connected_dim = 128\n","input_vocab_size = num_tokens_source\n","target_vocab_size = num_tokens_target\n","max_positional_encoding_input = max_source_length\n","max_positional_encoding_target = max_target_length"]},{"cell_type":"markdown","metadata":{"id":"Ly4vh0t85N3X"},"source":["<h3> Create Transformer object </h3>"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1660757266179,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"S8P8Bg8MYGf4","outputId":"77b53229-f388-493a-e52f-674d13b3d53e"},"outputs":[],"source":["transformer = Transformer(\n","    num_layers=num_layers,\n","    embedding_dim=embedding_dim,\n","    num_heads=num_heads,\n","    fully_connected_dim=fully_connected_dim,\n","    input_vocab_size=input_vocab_size,\n","    target_vocab_size=target_vocab_size,\n","    max_positional_encoding_input = max_positional_encoding_input,\n","    max_positional_encoding_target = max_positional_encoding_target\n","    )"]},{"cell_type":"markdown","metadata":{"id":"uvAuEWUwYGf5"},"source":["- Create optimizer"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1660757268527,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"8qYL_Vg7YGf5"},"outputs":[],"source":["# Use customised learning rate as defined in 'Attention Is All You Need' paper\n","# The learning rate increases linearly until training_step reaches \"warmup_steps\", then decays asymptotically\n","# Inputs: d_model, warmup_steps (default = 4000)\n","\n","learning_rate = CustomSchedule(embedding_dim, warmup_steps = 4000)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1660757270498,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"Ka5uNFNEYGf5"},"outputs":[],"source":["# define loss object\n","# from_logits = False, because we apply softmax to final Dense layer of Transformer\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=False, reduction='none')\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":272,"status":"ok","timestamp":1660757274023,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"objpWrBgYGf5"},"outputs":[],"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n","test_accuracy = tf.keras.metrics.Mean(name = 'test_accuracy')"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1660757275756,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"guju7vbIYGf5"},"outputs":[],"source":["@tf.function\n","def train_step(inp, tar):\n","                            # inp = (m, Tx)\n","                            # tar = (m, Ty)\n","\n","\n","  tar_inp = tar[:, :-1]     # \"start_\" to last word\n","  tar_real = tar[:, 1:]     # first word to \"_end\"\n","\n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inputs = (inp, tar_inp),\n","                                 training = True)\n","    loss = loss_function(tar_real, predictions, loss_object)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  acc = accuracy_function(tar_real, predictions)\n","\n","  # store cumulative loss and acc in train_loss and train_accuracy\n","  train_loss(loss)\n","  train_accuracy(acc)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":274,"status":"ok","timestamp":1660757277169,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"-jxQm8iSYGf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Latest checkpoint restored!\n"]}],"source":["checkpoint_path = './checkpoints'\n","\n","ckpt = tf.train.Checkpoint(optimizer=optimizer,\n","                                 transformer=transformer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep = 3)\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print('Latest checkpoint restored!')\n","else:\n","    print('Initialising from scratch')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./checkpoints/ckpt-40\n"]}],"source":["print(ckpt_manager.latest_checkpoint)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["epoch_batch_list = []\n","train_loss_list = []\n","train_acc_list = []\n","test_loss_list = []\n","test_acc_list = []"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1558553,"status":"error","timestamp":1660758836991,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"PXsDysBPYGf6","outputId":"a788c160-c44b-43be-931f-360a1b4922f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 0 -- Train_Loss: 2.8347 Train_Accuracy: 0.4646\n","Epoch 1 Batch 50 -- Train_Loss: 2.5686 Train_Accuracy: 0.4939\n","Saving checkpoint after epoch 1 at ./checkpoints/ckpt-46\n","Summary -- Epoch 1 Train_Loss: 2.5815 Train_Accuracy: 0.4910     Test_Loss: 5.7602 Test_Accuracy: 0.3099\n","Time taken for 1 epoch: 32.98 secs\n","\n","Epoch 2 Batch 0 -- Train_Loss: 2.2754 Train_Accuracy: 0.5318\n","Epoch 2 Batch 50 -- Train_Loss: 2.2276 Train_Accuracy: 0.5424\n","Saving checkpoint after epoch 2 at ./checkpoints/ckpt-47\n","Summary -- Epoch 2 Train_Loss: 2.2438 Train_Accuracy: 0.5390     Test_Loss: 5.9072 Test_Accuracy: 0.3090\n","Time taken for 1 epoch: 32.92 secs\n","\n","Epoch 3 Batch 0 -- Train_Loss: 2.0502 Train_Accuracy: 0.5761\n","Epoch 3 Batch 50 -- Train_Loss: 1.9334 Train_Accuracy: 0.5874\n","Saving checkpoint after epoch 3 at ./checkpoints/ckpt-48\n","Summary -- Epoch 3 Train_Loss: 1.9512 Train_Accuracy: 0.5825     Test_Loss: 6.1031 Test_Accuracy: 0.3076\n","Time taken for 1 epoch: 32.84 secs\n","\n","Epoch 4 Batch 0 -- Train_Loss: 1.8628 Train_Accuracy: 0.6055\n","Epoch 4 Batch 50 -- Train_Loss: 1.6857 Train_Accuracy: 0.6301\n","Saving checkpoint after epoch 4 at ./checkpoints/ckpt-49\n","Summary -- Epoch 4 Train_Loss: 1.7112 Train_Accuracy: 0.6241     Test_Loss: 6.4078 Test_Accuracy: 0.3046\n","Time taken for 1 epoch: 34.28 secs\n","\n","Epoch 5 Batch 0 -- Train_Loss: 1.6645 Train_Accuracy: 0.6503\n","Epoch 5 Batch 50 -- Train_Loss: 1.4965 Train_Accuracy: 0.6625\n","Saving checkpoint after epoch 5 at ./checkpoints/ckpt-50\n","Summary -- Epoch 5 Train_Loss: 1.5094 Train_Accuracy: 0.6590     Test_Loss: 6.5074 Test_Accuracy: 0.3031\n","Time taken for 1 epoch: 32.48 secs\n","\n"]}],"source":["EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  # reset tf Mean objects\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  train_accuracy.reset_states()\n","\n","  # iterate over every batch (= (inp, tar) tuple) in training dataset\n","  for (batch, (inp, tar)) in enumerate(dataset_train):\n","    train_step(inp, tar)\n","\n","    if batch % 50 == 0:\n","      print(f'Epoch {epoch + 1} Batch {batch} -- Train_Loss: {train_loss.result():.4f} Train_Accuracy: {train_accuracy.result():.4f}')\n","\n","\n","    # if batch % 5000 == 0:\n","    #   ckpt_save_path = ckpt_manager.save()\n","    #   print(f'Saving checkpoint after epoch {epoch +1} batch {batch} at {ckpt_save_path}')\n","\n","    if batch % 50 == 0:\n","      epoch_batch_list.append(f'epoch_{epoch+1}_batch_{batch}')\n","      train_loss_list.append (train_loss.result().numpy())\n","      train_acc_list.append(train_accuracy.result().numpy())\n","\n","      test_loss_list.append(test_loss.result().numpy())\n","      test_acc_list.append(test_accuracy.result().numpy())\n","\n","\n","  if (epoch+1) % 1 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print(f'Saving checkpoint after epoch {epoch + 1} at {ckpt_save_path}')\n","  \n","  # after one epoch of training, compute test loss and test acc\n","  for (batch, (inp, tar)) in enumerate(dataset_test):\n","    test_loss_batch, test_accuracy_batch = compute_test_metrics(inp, tar, transformer, loss_object)\n","    # Update tf Mean objects\n","    test_loss(test_loss_batch)\n","    test_accuracy(test_accuracy_batch)\n","  \n","\n","  print(f'Summary -- Epoch {epoch + 1} Train_Loss: {train_loss.result():.4f} Train_Accuracy: {train_accuracy.result():.4f} \\\n","    Test_Loss: {test_loss.result():.4f} Test_Accuracy: {test_accuracy.result():.4f}')\n","\n","  epoch_batch_list.append(f'end of epoch {epoch+1}')\n","  train_loss_list.append (train_loss.result().numpy())\n","  train_acc_list.append(train_accuracy.result().numpy())\n","\n","  test_loss_list.append(test_loss.result().numpy())\n","  test_acc_list.append(test_accuracy.result().numpy())\n","  \n","\n","\n","  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>epoch_batch</th>\n","      <th>train_loss</th>\n","      <th>train_acc</th>\n","      <th>test_loss</th>\n","      <th>test_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>epoch_1_batch_0</td>\n","      <td>7.058</td>\n","      <td>0.272</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>epoch_1_batch_50</td>\n","      <td>5.789</td>\n","      <td>0.258</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>end of epoch 1</td>\n","      <td>5.586</td>\n","      <td>0.267</td>\n","      <td>4.954</td>\n","      <td>0.314</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>epoch_2_batch_0</td>\n","      <td>4.450</td>\n","      <td>0.339</td>\n","      <td>0.000</td>\n","      <td>0.314</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>epoch_2_batch_50</td>\n","      <td>4.417</td>\n","      <td>0.327</td>\n","      <td>0.000</td>\n","      <td>0.314</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>end of epoch 2</td>\n","      <td>4.427</td>\n","      <td>0.327</td>\n","      <td>4.971</td>\n","      <td>0.317</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>epoch_3_batch_0</td>\n","      <td>4.005</td>\n","      <td>0.368</td>\n","      <td>0.000</td>\n","      <td>0.317</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>epoch_3_batch_50</td>\n","      <td>3.882</td>\n","      <td>0.367</td>\n","      <td>0.000</td>\n","      <td>0.317</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>end of epoch 3</td>\n","      <td>3.889</td>\n","      <td>0.366</td>\n","      <td>5.152</td>\n","      <td>0.315</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>epoch_4_batch_0</td>\n","      <td>3.584</td>\n","      <td>0.387</td>\n","      <td>0.000</td>\n","      <td>0.315</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>epoch_4_batch_50</td>\n","      <td>3.379</td>\n","      <td>0.407</td>\n","      <td>0.000</td>\n","      <td>0.315</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>end of epoch 4</td>\n","      <td>3.383</td>\n","      <td>0.407</td>\n","      <td>5.355</td>\n","      <td>0.314</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>epoch_5_batch_0</td>\n","      <td>3.100</td>\n","      <td>0.426</td>\n","      <td>0.000</td>\n","      <td>0.314</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>epoch_5_batch_50</td>\n","      <td>2.941</td>\n","      <td>0.447</td>\n","      <td>0.000</td>\n","      <td>0.314</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>end of epoch 5</td>\n","      <td>2.949</td>\n","      <td>0.449</td>\n","      <td>5.565</td>\n","      <td>0.312</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>epoch_1_batch_0</td>\n","      <td>2.835</td>\n","      <td>0.465</td>\n","      <td>0.000</td>\n","      <td>0.312</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>epoch_1_batch_50</td>\n","      <td>2.569</td>\n","      <td>0.494</td>\n","      <td>0.000</td>\n","      <td>0.312</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>end of epoch 1</td>\n","      <td>2.581</td>\n","      <td>0.491</td>\n","      <td>5.760</td>\n","      <td>0.310</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>epoch_2_batch_0</td>\n","      <td>2.275</td>\n","      <td>0.532</td>\n","      <td>0.000</td>\n","      <td>0.310</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>epoch_2_batch_50</td>\n","      <td>2.228</td>\n","      <td>0.542</td>\n","      <td>0.000</td>\n","      <td>0.310</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>end of epoch 2</td>\n","      <td>2.244</td>\n","      <td>0.539</td>\n","      <td>5.907</td>\n","      <td>0.309</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>epoch_3_batch_0</td>\n","      <td>2.050</td>\n","      <td>0.576</td>\n","      <td>0.000</td>\n","      <td>0.309</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>epoch_3_batch_50</td>\n","      <td>1.933</td>\n","      <td>0.587</td>\n","      <td>0.000</td>\n","      <td>0.309</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>end of epoch 3</td>\n","      <td>1.951</td>\n","      <td>0.583</td>\n","      <td>6.103</td>\n","      <td>0.308</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>epoch_4_batch_0</td>\n","      <td>1.863</td>\n","      <td>0.606</td>\n","      <td>0.000</td>\n","      <td>0.308</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>epoch_4_batch_50</td>\n","      <td>1.686</td>\n","      <td>0.630</td>\n","      <td>0.000</td>\n","      <td>0.308</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>end of epoch 4</td>\n","      <td>1.711</td>\n","      <td>0.624</td>\n","      <td>6.408</td>\n","      <td>0.305</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>epoch_5_batch_0</td>\n","      <td>1.664</td>\n","      <td>0.650</td>\n","      <td>0.000</td>\n","      <td>0.305</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>epoch_5_batch_50</td>\n","      <td>1.497</td>\n","      <td>0.662</td>\n","      <td>0.000</td>\n","      <td>0.305</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>end of epoch 5</td>\n","      <td>1.509</td>\n","      <td>0.659</td>\n","      <td>6.507</td>\n","      <td>0.303</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         epoch_batch  train_loss  train_acc  test_loss  test_acc\n","0    epoch_1_batch_0       7.058      0.272      0.000     0.000\n","1   epoch_1_batch_50       5.789      0.258      0.000     0.000\n","2     end of epoch 1       5.586      0.267      4.954     0.314\n","3    epoch_2_batch_0       4.450      0.339      0.000     0.314\n","4   epoch_2_batch_50       4.417      0.327      0.000     0.314\n","5     end of epoch 2       4.427      0.327      4.971     0.317\n","6    epoch_3_batch_0       4.005      0.368      0.000     0.317\n","7   epoch_3_batch_50       3.882      0.367      0.000     0.317\n","8     end of epoch 3       3.889      0.366      5.152     0.315\n","9    epoch_4_batch_0       3.584      0.387      0.000     0.315\n","10  epoch_4_batch_50       3.379      0.407      0.000     0.315\n","11    end of epoch 4       3.383      0.407      5.355     0.314\n","12   epoch_5_batch_0       3.100      0.426      0.000     0.314\n","13  epoch_5_batch_50       2.941      0.447      0.000     0.314\n","14    end of epoch 5       2.949      0.449      5.565     0.312\n","15   epoch_1_batch_0       2.835      0.465      0.000     0.312\n","16  epoch_1_batch_50       2.569      0.494      0.000     0.312\n","17    end of epoch 1       2.581      0.491      5.760     0.310\n","18   epoch_2_batch_0       2.275      0.532      0.000     0.310\n","19  epoch_2_batch_50       2.228      0.542      0.000     0.310\n","20    end of epoch 2       2.244      0.539      5.907     0.309\n","21   epoch_3_batch_0       2.050      0.576      0.000     0.309\n","22  epoch_3_batch_50       1.933      0.587      0.000     0.309\n","23    end of epoch 3       1.951      0.583      6.103     0.308\n","24   epoch_4_batch_0       1.863      0.606      0.000     0.308\n","25  epoch_4_batch_50       1.686      0.630      0.000     0.308\n","26    end of epoch 4       1.711      0.624      6.408     0.305\n","27   epoch_5_batch_0       1.664      0.650      0.000     0.305\n","28  epoch_5_batch_50       1.497      0.662      0.000     0.305\n","29    end of epoch 5       1.509      0.659      6.507     0.303"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["all_metrics = zip(epoch_batch_list, train_loss_list, train_acc_list, test_loss_list, test_acc_list)\n","df_metrics = pd.DataFrame(all_metrics, columns = ['epoch_batch', 'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n","df_metrics[['train_loss', 'train_acc', 'test_loss', 'test_acc']] = df_metrics[['train_loss', 'train_acc', 'test_loss', 'test_acc']].apply(lambda x: round(x,3))\n","df_metrics"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660748525271,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"9va6cEFqYGf6"},"outputs":[],"source":["df_metrics.to_csv('metrics/df_metrics.csv', index = False)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":2283,"status":"ok","timestamp":1660748527550,"user":{"displayName":"Kyung","userId":"01072507214168010723"},"user_tz":-120},"id":"C7NiFdQSYGf6"},"outputs":[],"source":["file_path = 'saved_models/model'\n","transformer.save_weights(file_path,save_format='tf')\n","\n","# # Recreate the exact same model purely from the file\n","# new_model = keras.models.load_model('path_to_my_model')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"train_v1.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.4 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"a30d934768a106a0bdaa0b54b1b0ce58ac936216b32c4f047caaf50b54e34c32"}}},"nbformat":4,"nbformat_minor":0}
