{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Overview </h3>\n",
    "\n",
    "- 1) Load and pre-process EuroParl data (as dataframe)\n",
    "- 2) Load and pre-process ManyThings data (as dataframe)\n",
    "- 3) Combine the two dataframes & process sentences\n",
    "- 4) Create German and English corpuses\n",
    "- 5) Create German and English tokenizers \n",
    "- 6) Save df_complete.csv\n",
    "- 7) Save df_complete_30.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer_helpers import preprocess_sentence, create_train_tokenizer, load_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1) EuroParl Data: Load & Pre-Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "\treturn doc.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_en = 'data/europarl_de-en/europarl-v7.de-en.en'\n",
    "text_en = load_doc(filename_en)\n",
    "doc_en = to_sentences(text_en)\n",
    "\n",
    "filename_de = 'data/europarl_de-en/europarl-v7.de-en.de'\n",
    "text_de = load_doc(filename_de)\n",
    "doc_de = to_sentences(text_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2923, 8366)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_languages = zip(doc_de, doc_en)\n",
    "df_euro_parl = pd.DataFrame(both_languages, columns = ['german', 'english'])\n",
    "\n",
    "# replace empty strings with NaN\n",
    "df_euro_parl['german'].replace('', np.nan, inplace=True)\n",
    "df_euro_parl['english'].replace('', np.nan, inplace=True)\n",
    "\n",
    "# check number of NaN values\n",
    "df_euro_parl['german'].isna().sum(), df_euro_parl['english'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values\n",
    "df_euro_parl = df_euro_parl.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2) ManyThings Data: Load & Pre-Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ManyThings = pd.read_table('data/deu-eng/deu.txt', names=['eng', 'deu', 'attr'])\n",
    "df_ManyThings = df_ManyThings.drop('attr',axis = 1).rename(columns = {'eng':'english', 'deu':'german'})\n",
    "\n",
    "# switch order of columns\n",
    "df_ManyThings = df_ManyThings[['german', 'english']]\n",
    "\n",
    "# replace empty strings with NaN\n",
    "df_ManyThings['german'].replace('', np.nan, inplace=True)\n",
    "df_ManyThings['english'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of NaN values\n",
    "df_ManyThings['german'].isna().sum(), df_ManyThings['english'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3) Combine the two dataframes + further pre-process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.concat([df_euro_parl, df_ManyThings], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data \n",
    "# Here I'm using my \"preprocess_sentence\" function, imported from \"model_components\"\n",
    "df_complete['german'] = df_complete['german'].apply(preprocess_sentence)\n",
    "df_complete['english'] = df_complete['english'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run time: 57 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wir haben Vertrauen zur Kommission, zu Romano Prodi, und die ganz grosse Mehrheit unserer Fraktion hat Romano Prodi und der Kommission nach einem schwierigen Prozess, wie jeder weiss, das Vertrauen ausgesprochen.\n",
      "We have confidence in the Commission and in Romano Prodi and, after a difficult procedure, as everyone knows, the vast majority of our Group supported the vote of confidence in Romano Prodi and the Commission.\n",
      "Aber wir sind auch der Meinung, dass wir eine Debatte ueber diese Strategie der Kommission in einem geordneten Verfahren fuehren muessen, nicht nur aufgrund einer muendlichen Erklaerung hier im Europaeischen Parlament, sondern auch aufgrund eines Dokumentes, das in der Kommission beschlossen ist und dieses Programm fuer fuenf Jahre beschreibt.\n",
      "We believe, however, that the Commission ' s strategic plan needs to be debated within a proper procedural framework, not only on the basis of an oral statement here in the European Parliament, but also on the basis of a document which is adopted in the Commission and which describes this programme over the five-year period.\n"
     ]
    }
   ],
   "source": [
    "# check some random examples\n",
    "\n",
    "for i in range (100, 102):\n",
    "    print(df_complete.iloc[i,0])\n",
    "    print( df_complete.iloc[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4) Create English and German corpuses </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create corpus for english and german to train BPE tokenizers on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('corpus/en_corpus.txt', 'w') as f:\n",
    "    for idx, row in df_complete.iterrows():\n",
    "        f.write(row['english'] + ' \\n')\n",
    "\n",
    "with open ('corpus/de_corpus.txt', 'w') as f:\n",
    "    for idx, row in df_complete.iterrows():\n",
    "        f.write(row['german'] + ' \\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run time: 1m 16 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 5) Create German and English tokenizers based on the corpuses </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "json file saved at: tokenizers/tokenizer_en_corpus.json\n",
      "\n",
      "\n",
      "\n",
      "json file saved at: tokenizers/tokenizer_de_corpus.json\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizers \n",
    "# Here I'm using my \"create_train_tokenizer\" function from \"model_components\"\n",
    "en_tokenizer = create_train_tokenizer(['corpus/en_corpus.txt'])\n",
    "de_tokenizer = create_train_tokenizer(['corpus/de_corpus.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['start_',\n",
       "  'In',\n",
       "  'Ġdiesem',\n",
       "  'ĠSinne',\n",
       "  'Ġ,',\n",
       "  'Ġmoechte',\n",
       "  'Ġich',\n",
       "  'ĠSie',\n",
       "  'Ġbitten',\n",
       "  ',',\n",
       "  'Ġnur',\n",
       "  'Ġauf',\n",
       "  'Ġkurz',\n",
       "  'erer',\n",
       "  'ĠZeit',\n",
       "  'Ġeine',\n",
       "  'ĠMa',\n",
       "  'il',\n",
       "  'Ġzu',\n",
       "  'Ġschicken',\n",
       "  '.',\n",
       "  '_end'],\n",
       " [1,\n",
       "  761,\n",
       "  630,\n",
       "  3086,\n",
       "  2126,\n",
       "  585,\n",
       "  406,\n",
       "  589,\n",
       "  3201,\n",
       "  14,\n",
       "  633,\n",
       "  359,\n",
       "  1876,\n",
       "  8181,\n",
       "  842,\n",
       "  390,\n",
       "  977,\n",
       "  472,\n",
       "  300,\n",
       "  12817,\n",
       "  16,\n",
       "  2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test tokenizers\n",
    "# Here I'm using my \"load_tokenizer\" function imported from \"model_components\"\n",
    "\n",
    "# load tokenizers\n",
    "en_tokenizer, en_word_index = load_tokenizer('tokenizers/tokenizer_en_corpus.json')\n",
    "de_tokenizer, de_word_index = load_tokenizer('tokenizers/tokenizer_de_corpus.json')\n",
    "\n",
    "# random German sentence \n",
    "sentence = \"In diesem      Sinne   , möchte ich Sie bitten, nur auf kurzerer Zeit eine Mail zu schicken.\"\n",
    "# pre-process\n",
    "sentence = preprocess_sentence(sentence)\n",
    "\n",
    "# encode using my loaded tokenizer\n",
    "output = de_tokenizer.encode(sentence)\n",
    "\n",
    "# view tokens and ids\n",
    "output.tokens, output.ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 6) Save df_complete as csv file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv('data/df_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.read_csv('data/df_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "german     2\n",
       "english    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mysteriously, there are two nan values. We'll simply drop them.\n",
    "df_complete = df_complete.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv('df_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 7) Create dataframe with capped sentence length </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_30 = df_complete.copy(deep = True)\n",
    "df_complete_30['german_length'] = df_complete['german'].apply(lambda x: len(x.split(' ')))\n",
    "df_complete_30['english_length'] = df_complete['english'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>german</th>\n",
       "      <th>english</th>\n",
       "      <th>german_length</th>\n",
       "      <th>english_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erklaere die am Freitag, dem 17. Dezember ...</td>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie Sie feststellen konnten, ist der gefuercht...</td>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Im Parlament besteht der Wunsch nach einer Aus...</td>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heute moechte ich Sie bitten - das ist auch de...</td>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              german  \\\n",
       "0                 Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erklaere die am Freitag, dem 17. Dezember ...   \n",
       "2  Wie Sie feststellen konnten, ist der gefuercht...   \n",
       "3  Im Parlament besteht der Wunsch nach einer Aus...   \n",
       "4  Heute moechte ich Sie bitten - das ist auch de...   \n",
       "\n",
       "                                             english  german_length  \\\n",
       "0                          Resumption of the session              3   \n",
       "1  I declare resumed the session of the European ...             29   \n",
       "2  Although, as you will have seen, the dreaded '...             22   \n",
       "3  You have requested a debate on this subject in...             16   \n",
       "4  In the meantime, I should like to observe a mi...             33   \n",
       "\n",
       "   english_length  \n",
       "0               4  \n",
       "1              38  \n",
       "2              31  \n",
       "3              19  \n",
       "4              40  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_30 = (df_complete_30['german_length'] <= 30) & (df_complete_30['english_length'] <= 30)\n",
    "df_complete_30 = df_complete_30[mask_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160638, 1562141)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_complete), len(df_complete_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_30.to_csv('data/df_complete_30.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a30d934768a106a0bdaa0b54b1b0ce58ac936216b32c4f047caaf50b54e34c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
